{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: XGBoost Model Training and Deployment on AWS SageMaker\n",
    "\n",
    "This project demonstrates an end-to-end machine learning pipeline using Amazon SageMaker to train, tune, and deploy an XGBoost model for a classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter, IntegerParameter\n",
    "from sagemaker.xgboost import XGBoost\n",
    "from sagemaker.model import Model\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "We start by loading the dataset and performing basic preprocessing steps, such as dropping unnecessary columns, handling missing values, and extracting relevant features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Download the SBA-Loans-Case-Data-Set from OpenML\n",
    "data = fetch_openml(data_id=43539, as_frame=True)\n",
    "df = data.data\n",
    "\n",
    "# Inspect the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/raw_data.csv')\n",
    "df.drop(columns=['Selected', 'ChgOffDate', 'LoanNr_ChkDgt', 'Name'], inplace=True)\n",
    "df['NAICS'] = df['NAICS'].astype(str).str[:2].astype(int)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df.to_csv('data/processed_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Next, we split the data into training and validation sets, train an XGBoost model, and save the model for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Default'])\n",
    "y = df['Default']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n",
    "model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=10)\n",
    "model.save_model('xgb_model.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "We use Amazon SageMaker to perform hyperparameter tuning, optimizing the model's performance by searching for the best hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator = XGBoost(entry_point='train.py',\n",
    "                        role='your-role-arn',\n",
    "                        instance_count=1,\n",
    "                        instance_type='ml.m5.xlarge',\n",
    "                        framework_version='1.3-1',\n",
    "                        py_version='py3')\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'eta': ContinuousParameter(0, 1),\n",
    "    'min_child_weight': ContinuousParameter(1, 10),\n",
    "    'max_depth': IntegerParameter(1, 10)\n",
    "}\n",
    "\n",
    "tuner = HyperparameterTuner(estimator=xgb_estimator,\n",
    "                            objective_metric_name='validation:logloss',\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            max_jobs=10,\n",
    "                            max_parallel_jobs=2)\n",
    "\n",
    "tuner.fit({'train': 's3://your-bucket/train', 'validation': 's3://your-bucket/validation'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment\n",
    "\n",
    "After tuning the hyperparameters, we deploy the trained model to an AWS SageMaker endpoint to make it accessible for inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Model(model_data='s3://your-bucket/xgb_model.tar.gz',\n",
    "              role='your-role-arn',\n",
    "              image_uri=sagemaker.image_uris.retrieve('xgboost', sagemaker.Session().boto_region_name, version=\"1.3-1\"))\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge', endpoint_name='your-endpoint-name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollback Testing\n",
    "\n",
    "We test the deployment guardrails by sending test traffic to the endpoint under both a failed and successful rollback scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating a failed deployment scenario\n",
    "def invoke_endpoint(endpoint_name, max_invocations=600, wait_interval_sec=1, should_raise_exp=False):\n",
    "    print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "\n",
    "    count = 0\n",
    "    with open(\"test_X_numeric.csv\", \"r\") as f:\n",
    "        for row in f:\n",
    "            payload = row.rstrip(\"\\n\")\n",
    "            try:\n",
    "                response = sm_runtime.invoke_endpoint(\n",
    "                    EndpointName=endpoint_name, ContentType=\"text/csv\", Body=payload\n",
    "                )\n",
    "                response[\"Body\"].read()\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "            except Exception as e:\n",
    "                print(\"E\", end=\"\", flush=True)\n",
    "                if should_raise_exp:\n",
    "                    raise e\n",
    "            count += 1\n",
    "            if count > max_invocations:\n",
    "                break\n",
    "            time.sleep(wait_interval_sec)\n",
    "\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "invoke_endpoint(\"DEMO-Deployment-Guardrails-Canary-2024-04-15-18-01-04\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating a successful deployment scenario\n",
    "invoke_endpoint(\"DEMO-Deployment-Guardrails-Canary-2024-04-15-18-01-04\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Finally, we send a payload to the deployed endpoint to perform inference and obtain predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "runtime = boto3.client('sagemaker-runtime')\n",
    "response = runtime.invoke_endpoint(EndpointName='your-endpoint-name', ContentType='text/csv', Body='your-csv-data-here')\n",
    "print(response['Body'].read())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
